name: Nightly Comprehensive Tests

on:
  schedule:
    # Run every day at 2:00 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual triggering

permissions:
  contents: read
  issues: write

jobs:
  comprehensive-tests:
    name: Comprehensive Test Suite
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ['3.11', '3.12', '3.13']
        exclude:
          # Reduce matrix size - skip some combinations
          - os: macos-latest
            python-version: '3.13'
          - os: windows-latest
            python-version: '3.13'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install uv (Unix)
        if: runner.os != 'Windows'
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install uv (Windows)
        if: runner.os == 'Windows'
        run: |
          irm https://astral.sh/uv/install.ps1 | iex
          echo "$env:USERPROFILE\.cargo\bin" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/uv
            ~/.cache/pip
          key: ${{ runner.os }}-py${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-py${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          uv pip install --system -e ".[dev]"

      - name: Run comprehensive tests
        run: |
          pytest tests/ -v -n auto \
            --cov=cancrizans \
            --cov-report=term-missing \
            --cov-report=xml \
            --cov-report=html \
            --junitxml=test-results-${{ matrix.os }}-${{ matrix.python-version }}.xml \
            --durations=20 \
            --tb=long \
            --strict-markers \
            --strict-config

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
          path: |
            test-results-*.xml
            htmlcov/
          retention-days: 30

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage.xml
          flags: nightly,${{ matrix.os }},python-${{ matrix.python-version }}
          name: ${{ matrix.os }}-${{ matrix.python-version }}
          fail_ci_if_error: false

  extended-tests:
    name: Extended Integration Tests
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv pip install --system -e ".[dev]"

      - name: Run all CLI commands
        run: |
          # Test all CLI commands with various options
          echo "Testing CLI commands..."

          # Generate various canons
          cancrizans generate scale --output /tmp/scale.mid
          cancrizans generate fibonacci --output /tmp/fib.mid
          cancrizans generate golden --output /tmp/golden.mid
          cancrizans generate modal --output /tmp/modal.mid

          # Validate them
          cancrizans validate /tmp/scale.mid
          cancrizans validate /tmp/fib.mid

          # Analyze patterns
          cancrizans analyze-patterns /tmp/scale.mid --all --verbose

          # Test research command with batch processing
          mkdir -p /tmp/research-output
          cancrizans research analyze-corpus /tmp/*.mid --output /tmp/research-output

      - name: Test notebook execution
        run: |
          # Install jupyter for notebook testing
          pip install jupyter nbconvert

          # Execute all notebooks to ensure they work
          for notebook in notebooks/*.ipynb; do
            echo "Testing: $notebook"
            jupyter nbconvert --to notebook --execute --inplace "$notebook" || echo "Warning: $notebook failed"
          done

      - name: Memory profiling
        run: |
          pip install memory_profiler

          # Run memory-intensive operations
          python << 'EOF'
          from memory_profiler import profile
          from cancrizans import CanonGenerator, detect_motifs

          gen = CanonGenerator()

          # Test large canon generation
          canon = gen.generate_scale_canon('C', 'major', length=100)
          print(f"Generated large canon: {len(list(canon.flatten().notes))} notes")

          # Test pattern analysis on large score
          result = detect_motifs(canon, min_length=3, max_length=8)
          print(f"Found {result['num_motifs']} motifs")
          EOF

  benchmark-regression:
    name: Benchmark Regression Check
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH
          uv pip install --system -e ".[dev]"

      - name: Run benchmarks
        run: |
          python benchmarks/benchmark_suite.py | tee benchmark_output.txt

      - name: Download previous benchmarks
        uses: dawidd6/action-download-artifact@v3
        continue-on-error: true
        with:
          workflow: nightly.yml
          name: nightly-benchmarks
          path: previous-benchmarks/
          if_no_artifact_found: warn

      - name: Compare benchmarks
        run: |
          if [ -f previous-benchmarks/benchmark_results.json ]; then
            python << 'EOF'
          import json
          from pathlib import Path

          current = json.loads(Path('benchmarks/results/benchmark_results.json').read_text())
          previous = json.loads(Path('previous-benchmarks/benchmark_results.json').read_text())

          print("=" * 70)
          print("BENCHMARK COMPARISON")
          print("=" * 70)

          regressions = []
          current_benchmarks = {b['name']: b for b in current['benchmarks']}
          previous_benchmarks = {b['name']: b for b in previous['benchmarks']}

          for name, curr in current_benchmarks.items():
              if name in previous_benchmarks:
                  prev = previous_benchmarks[name]
                  curr_time = curr['avg_duration'] * 1000
                  prev_time = prev['avg_duration'] * 1000
                  change_pct = ((curr_time - prev_time) / prev_time) * 100

                  emoji = "âœ…" if abs(change_pct) < 5 else "ðŸš€" if change_pct < 0 else "âš ï¸"
                  print(f"{emoji} {name[:50]:<50} {change_pct:+6.1f}%")

                  if change_pct > 15:  # More than 15% slower
                      regressions.append((name, change_pct))

          if regressions:
              print("\nâš ï¸  PERFORMANCE REGRESSIONS DETECTED:")
              for name, pct in regressions:
                  print(f"  - {name}: {pct:+.1f}% slower")
              exit(1)
          else:
              print("\nâœ… No significant performance regressions")
          EOF
          else
            echo "No previous benchmarks found for comparison"
          fi

      - name: Upload benchmarks
        uses: actions/upload-artifact@v4
        with:
          name: nightly-benchmarks
          path: benchmarks/results/benchmark_results.json
          retention-days: 90

  report:
    name: Nightly Test Report
    runs-on: ubuntu-latest
    needs: [comprehensive-tests, extended-tests, benchmark-regression]
    if: always()
    steps:
      - name: Create issue on failure
        if: needs.comprehensive-tests.result == 'failure' || needs.extended-tests.result == 'failure' || needs.benchmark-regression.result == 'failure'
        uses: actions/github-script@v7
        with:
          script: |
            const title = `ðŸŒ™ Nightly Test Failure - ${new Date().toISOString().split('T')[0]}`;
            const body = `## Nightly Test Suite Failed

            **Date:** ${new Date().toISOString()}

            **Failed Jobs:**
            - Comprehensive Tests: ${{ needs.comprehensive-tests.result }}
            - Extended Tests: ${{ needs.extended-tests.result }}
            - Benchmark Regression: ${{ needs.benchmark-regression.result }}

            **Action Required:**
            Please review the [workflow run](${context.payload.repository.html_url}/actions/runs/${context.runId}) for details.

            ---
            *This issue was automatically created by the nightly test workflow.*
            `;

            // Check if an issue already exists for today
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'nightly-failure',
            });

            const today = new Date().toISOString().split('T')[0];
            const existingIssue = issues.data.find(issue => issue.title.includes(today));

            if (!existingIssue) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['type: ci/cd', 'priority: high', 'nightly-failure'],
              });
            }

      - name: Post success notification
        if: needs.comprehensive-tests.result == 'success' && needs.extended-tests.result == 'success' && needs.benchmark-regression.result == 'success'
        run: |
          echo "âœ… All nightly tests passed successfully!"
