name: Comprehensive Test Matrix

on:
  schedule:
    # Monthly on the 1st at 04:00 UTC
    - cron: '0 4 1 * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Test type to run'
        required: false
        type: choice
        options:
          - all
          - compatibility
          - performance
          - integration
        default: 'all'

permissions:
  contents: read
  issues: write

jobs:
  matrix-setup:
    name: Setup Test Matrix
    runs-on: ubuntu-latest
    outputs:
      python-versions: ${{ steps.setup.outputs.python-versions }}
      os-matrix: ${{ steps.setup.outputs.os-matrix }}

    steps:
      - name: Setup matrix
        id: setup
        run: |
          # Python versions to test
          echo 'python-versions=["3.11", "3.12", "3.13"]' >> $GITHUB_OUTPUT

          # OS matrix
          echo 'os-matrix=["ubuntu-latest", "macos-latest", "windows-latest"]' >> $GITHUB_OUTPUT

  compatibility-tests:
    name: Python ${{ matrix.python }} on ${{ matrix.os }}
    needs: matrix-setup
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'compatibility' || github.event.inputs.test_type == ''
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        python: ${{ fromJson(needs.matrix-setup.outputs.python-versions) }}
        os: ${{ fromJson(needs.matrix-setup.outputs.os-matrix) }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run compatibility tests
        run: |
          pytest tests/ -v --tb=short -m "not slow" \
            --junitxml=test-results-${{ matrix.os }}-${{ matrix.python }}.xml

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.os }}-py${{ matrix.python }}
          path: test-results-*.xml
          retention-days: 30

  dependency-versions:
    name: Test with Different Dependency Versions
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'compatibility' || github.event.inputs.test_type == ''
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        deps:
          - name: minimum
            install: pip install music21==9.1.0 mido==1.3.0 matplotlib==3.8.0 numpy==1.26.0
          - name: latest
            install: pip install music21 mido matplotlib numpy --upgrade
          - name: bleeding-edge
            install: pip install --pre music21 mido matplotlib numpy || pip install music21 mido matplotlib numpy --upgrade

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python environment
        uses: ./.github/actions/setup-python-env

      - name: Install specific dependency versions (${{ matrix.deps.name }})
        run: |
          ${{ matrix.deps.install }}
          pip install -e ".[dev]"

      - name: Show installed versions
        run: |
          pip list | grep -E "(music21|mido|matplotlib|numpy)"

      - name: Run tests
        run: |
          pytest tests/ -v --tb=short -x

  edge-cases:
    name: Edge Case Testing
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'integration' || github.event.inputs.test_type == ''
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python environment
        uses: ./.github/actions/setup-python-env

      - name: Test with empty inputs
        run: |
          python << 'PYEOF'
          from cancrizans import retrograde
          from music21 import stream

          # Test with empty stream
          empty = stream.Stream()
          try:
              result = retrograde(empty)
              print("‚úì Empty stream handled")
          except Exception as e:
              print(f"‚úó Empty stream failed: {e}")

          # Test with single note
          single = stream.Stream()
          from music21 import note
          single.append(note.Note('C4'))
          try:
              result = retrograde(single)
              print("‚úì Single note handled")
          except Exception as e:
              print(f"‚úó Single note failed: {e}")
          PYEOF

      - name: Test with large inputs
        run: |
          python << 'PYEOF'
          from cancrizans.generator import CanonGenerator
          from music21 import stream

          gen = CanonGenerator(seed=42)

          # Test with large canon
          try:
              large_canon = gen.generate_scale_canon(root='C4', scale='major', length=1000)
              print(f"‚úì Large canon generated: {len(large_canon.notes)} notes")
          except Exception as e:
              print(f"‚úó Large canon failed: {e}")
          PYEOF

      - name: Test concurrent operations
        run: |
          python << 'PYEOF'
          from concurrent.futures import ThreadPoolExecutor
          from cancrizans.generator import CanonGenerator

          def generate_canon(seed):
              gen = CanonGenerator(seed=seed)
              return gen.generate_scale_canon(root='C4', scale='major', length=16)

          # Test thread safety
          try:
              with ThreadPoolExecutor(max_workers=4) as executor:
                  futures = [executor.submit(generate_canon, i) for i in range(10)]
                  results = [f.result() for f in futures]
              print(f"‚úì Concurrent operations: {len(results)} canons generated")
          except Exception as e:
              print(f"‚úó Concurrent operations failed: {e}")
          PYEOF

  stress-tests:
    name: Stress Testing
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'performance' || github.event.inputs.test_type == ''
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python environment
        uses: ./.github/actions/setup-python-env

      - name: Run stress tests
        run: |
          python << 'PYEOF'
          import time
          from cancrizans.generator import CanonGenerator
          from cancrizans import retrograde

          print("### Stress Test Results\n")

          # Test 1: Rapid canon generation
          gen = CanonGenerator(seed=42)
          start = time.time()
          for i in range(100):
              canon = gen.generate_scale_canon(root='C4', scale='major', length=16)
          elapsed = time.time() - start
          print(f"- Generated 100 canons in {elapsed:.2f}s ({100/elapsed:.1f} canons/sec)")

          # Test 2: Large canon operations
          large_canon = gen.generate_scale_canon(root='C4', scale='major', length=500)
          start = time.time()
          for i in range(10):
              reversed_canon = retrograde(large_canon)
          elapsed = time.time() - start
          print(f"- 10 retrograde operations on 500-note canon: {elapsed:.2f}s")

          # Test 3: Memory stress
          canons = []
          for i in range(50):
              canons.append(gen.generate_scale_canon(root='C4', scale='major', length=100))
          print(f"- Created 50 canons (100 notes each) in memory")
          PYEOF

  integration-matrix:
    name: Integration Tests
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'integration' || github.event.inputs.test_type == ''
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python environment
        uses: ./.github/actions/setup-python-env

      - name: Test CLI integration
        run: |
          # Test all CLI commands
          cancrizans --help
          cancrizans --version
          cancrizans scales --list-tunings
          cancrizans generate scale --output /tmp/test.mid --length 8
          cancrizans validate /tmp/test.mid
          cancrizans analyze-patterns /tmp/test.mid --all --output /tmp/analysis.json

          echo "‚úÖ All CLI commands executed successfully"

      - name: Test module imports
        run: |
          python << 'PYEOF'
          # Test all public imports
          from cancrizans import (
              load_bach_crab_canon,
              retrograde,
              inversion,
              augmentation,
              diminution,
              is_time_palindrome,
              table_canon,
              advanced_crab_canon,
              assemble_crab_from_theme,
              TransformationChain
          )

          from cancrizans.io import (
              to_midi,
              to_musicxml,
              to_lilypond,
              to_abc,
              from_midi
          )

          from cancrizans.viz import piano_roll, symmetry

          from cancrizans.generator import CanonGenerator
          from cancrizans.validator import CanonValidator

          print("‚úÖ All public imports successful")
          PYEOF

  generate-report:
    name: Generate Comprehensive Report
    needs: [compatibility-tests, dependency-versions, edge-cases, stress-tests, integration-matrix]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Generate summary report
        run: |
          cat > comprehensive_test_report.md << 'EOF'
          # üìä Comprehensive Test Matrix Report

          ## Test Results Summary

          | Test Suite | Status |
          |------------|--------|
          | Compatibility Tests | ${{ needs.compatibility-tests.result }} |
          | Dependency Versions | ${{ needs.dependency-versions.result }} |
          | Edge Cases | ${{ needs.edge-cases.result }} |
          | Stress Tests | ${{ needs.stress-tests.result }} |
          | Integration Tests | ${{ needs.integration-matrix.result }} |

          ## Overall Status

          EOF

          # Check if all passed
          if [ "${{ needs.compatibility-tests.result }}" = "success" ] && \
             [ "${{ needs.dependency-versions.result }}" = "success" ] && \
             [ "${{ needs.edge-cases.result }}" = "success" ] && \
             [ "${{ needs.stress-tests.result }}" = "success" ] && \
             [ "${{ needs.integration-matrix.result }}" = "success" ]; then
            echo "‚úÖ **All tests passed!**" >> comprehensive_test_report.md
          else
            echo "‚ùå **Some tests failed. Review the results above.**" >> comprehensive_test_report.md
          fi

          cat comprehensive_test_report.md >> $GITHUB_STEP_SUMMARY

      - name: Create issue if tests failed
        if: |
          needs.compatibility-tests.result == 'failure' ||
          needs.dependency-versions.result == 'failure' ||
          needs.edge-cases.result == 'failure' ||
          needs.stress-tests.result == 'failure' ||
          needs.integration-matrix.result == 'failure'
        uses: actions/github-script@v7
        with:
          script: |
            const body = `## ‚ö†Ô∏è Comprehensive Test Matrix Failed

            The monthly comprehensive test matrix has detected failures.

            **Failed Test Suites:**
            - Compatibility Tests: ${{ needs.compatibility-tests.result }}
            - Dependency Versions: ${{ needs.dependency-versions.result }}
            - Edge Cases: ${{ needs.edge-cases.result }}
            - Stress Tests: ${{ needs.stress-tests.result }}
            - Integration Tests: ${{ needs.integration-matrix.result }}

            [View Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

            Please investigate and fix the failing tests.
            `;

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '‚ö†Ô∏è Comprehensive Test Matrix Failed',
              body: body,
              labels: ['testing', 'automated', 'needs-investigation']
            });
